Load the data and set the needed variables.

```{r}
R02_00 <- "../R/02_00_load_data.R"
source(R02_00)
```

```{r}
cat(paste0("  CODE FILENAME: ", R02_00, paste(rep("-", 41), collapse = "")))
cat(paste(readLines(R02_00), collapse="\n"),collapse = "\n")
cat(paste0("  ", "end",paste(rep("-", 73), collapse = "")))
```

## Estimate $S_0$

Fit the regression model and estimate $S_0$. Call this estimate $\hat S_0$.

```{r}
R02_01 <- "../R/02_01_stable.R"
source(R02_01)
```

```{r}
cat(paste0("  CODE FILENAME: ", R02_01, paste(rep("-", 41), collapse = "")))
cat(paste(readLines(R02_01), collapse="\n"),collapse = "\n")
cat(paste0("  ", "end",paste(rep("-", 73), collapse = "")))
```

The above code yields $\hat {\beta_0}=$ `r beta_hat[1]` and $\hat \beta_1=$ `r beta_hat[2]`.

Stable state: Let $S_0 = R_0 \rightarrow \frac{1}{S_0} = \frac{1}{R_0} \leftrightarrow x_0 = y_0$:


\begin{equation}
\begin{aligned}
y_0 &= \hat {\beta_0} + \hat {\beta_1} x_0 \\
y_0 &= \hat {\beta_0} + \hat {\beta_1} y_0 \\
y_0 - \hat {\beta_1} y_0 &= \hat {\beta_0} \\
y_0(1 - \hat {\beta_1}) &= \hat {\beta_0} \\
\hat y_0 &= \frac{\hat {\beta_0}}{1 - \hat {\beta_1}}
\end{aligned}
\end{equation} 


It follows by substitution and more algebra that,


\begin{equation}
\begin{aligned}
\frac{\hat {\beta_0}}{1 - \hat {\beta_1}} &= \hat {\beta_0} + \hat {\beta_1} x_0 \\
\frac{\frac{\hat {\beta_0}}{1 - \hat {\beta_1}} - \hat {\beta_0}}{\hat \beta_1} &= \hat x_0 \\
\end{aligned}
\end{equation}


Hence,

\begin{equation}
\begin{aligned}
(\hat x_0, \hat y_0) = \left(\frac{\frac{\hat {\beta_0}}{1 - \hat {\beta_1}} - \hat {\beta_0}}{\hat \beta_1}, 
\frac{\hat {\beta_0}}{1 - \hat {\beta_1}}\right) \iff \\
(\hat S_0, \hat R_0) = \left( \frac{1}{\frac{\frac{\hat {\beta_0}}{1 - \hat {\beta_1}} - \hat {\beta_0}}{\hat \beta_1}}, 
\frac{1}{\frac{\hat {\beta_0}}{1 - \hat {\beta_1}}} \right) \label{eq:stable}
\end{aligned}
\end{equation}

Substituting the values of $\hat {\beta_0}$ and $\hat {\beta_0}$ to equation \ref{eq:stable}, we get $\hat S_0 =$ `r S_0` and $\hat R_0 =$ `r R_0`; they are equal, by definition of stable state.


## Bootstrap estimate of SE

Use the bootstrap to obtain an estimate of the standard error of $\hat S_0$. Use $B = 2000$ bootstrap
samples.

  * This is nonparametric bootstrap since it is mentioned that no distribution is assumed.
  * It is also mentioned that $S$ variable can be considered as fixed; as a result, we will do SRSWR from the empirical distribution of the residuals.
  
The algorithm is already given in the regression handout, case 1a. In addition to that, we have to calculate the value $\hat S^*_0$, through equation \ref{eq:stable}, but for each bootstrap sample.
  
```{r}
R02_02 <- "../R/02_02_se_estimate.R"
source(R02_02)
```

```{r}
cat(paste0("  CODE FILENAME: ", R02_02, paste(rep("-", 41), collapse = "")))
cat(paste(readLines(R02_02), collapse="\n"),collapse = "\n")
cat(paste0("  ", "end",paste(rep("-", 73), collapse = "")))
```

The bootstrap estimate of the standard error is `r stable_se`.

## Histogram

The histogram has a symmetric bell curve shape. This is expected to be centered around $\hat S_0 =$ `r S_0`. Indeed, the mean of the distribution below is `r mean(S_0_star)`.

```{r echo = FALSE}
hist(
  S_0_star,
  main = expression(paste("Histogram of ", hat(S)[0], "*")),
  xlab = expression(paste(hat(S)[0], "*")))
```

## Confidence Intervals

We are $95\%$ confident that the true value of $S_0$ is between `r stable_ci[1]` and `r stable_ci[2]`. Since the values being dealt with are large, in my perspective, interval is neither too broad nor too narrow.








