## bootstrap-t method

Compute a 95% CI for $\theta$ using the bootstrap-$t$ method. Use $B_1 = 1000$ first-level bootstrap samples and $B_2 = 50$ second level bootstrap samples (to estimate the standard error). Interpret the CI.

```{r}
survival_times <- c(10, 27, 30, 40, 46, 51, 52, 104, 146)
sample_median <- median(survival_times)
sample_median
```

```{r}

set.seed(1000)
boot_fn <- function(i) {
  #taking 1st level boot
  law.boot <- sample(survival_times, n, replace = TRUE)
  r.boot <- median(law.boot)

  #taking 2nd level boot
  r.boot2 <- replicate(B2, {
    law.boot2 <- sample(law.boot, n, replace = TRUE)
    median(law.boot2)
  })

  se.boot <- sd(r.boot2)
  t.boot <- (r.boot - r) / se.boot
  
  result_list <- list(r = r.boot, t = t.boot)

  return(result_list)
}
```



```{r}

B1 <- 1000
B2 <- 50
n <- 9
r <- sample_median
set.seed(7)
startTime <- Sys.time()
res = sapply(1:1000, boot_fn)
endTime <- Sys.time()
endTime - startTime
ses <- unlist(res[1,])
tbs <- unlist(res[2,])

se.r <- sd(ses) #bootstrap estimate of the SE
lower <- sample_median - quantile(tbs,.975)*se.r
upper <- sample_median - quantile(tbs,.025)*se.r
c(lower,upper)

```

## bootstrap percentile CI

Compute a 95% CI for $\theta$ using the bootstrap percentile CI with B = 1000 bootstrap samples.
Interpret the CI.

```{r}
percentile_ci <- function(estimate = "median") {
  #taking 1st level boot
  law.boot <- sample(survival_times, n, replace = TRUE)
  
  if (estimate == "median") {
    r.boot <- median(law.boot)
  } else if (estimate == "mean") {
    r.boot <- mean(law.boot)
  }
  
  return(r.boot)
}
```

```{r}
startTime <- Sys.time()
set.seed(7)
res_median = sapply(1:1000, function(.){percentile_ci(estimate = "median")})
endTime <- Sys.time()
endTime - startTime
c(quantile(res,.025),quantile(res,.975))
```

## mean time between failures

Compute a 95% confidence interval for the mean time between failures $\theta$ using the basic bootstrap method with B = 1000 bootstrap samples. Interpret the CI.

```{r}
startTime <- Sys.time()
set.seed(7)
res_mean = sapply(1:1000, function(.){percentile_ci(estimate = "mean")})
endTime <- Sys.time()
endTime - startTime
c(quantile(res,.025),quantile(res,.975))
```


## density estimate


Plot a density estimate of the data. In R, you can do this through the density function. Compare
the results in parts (a), (b), and (c). If there is a difference in the results, does it have to do with the shape of the data?

```{r}
hist(tbs)
plot(density(tbs))
```


```{r}
hist(res_median)
plot(density(res_median))
```

```{r}
hist(res_mean)
plot(density(res_mean))
```

















Algorithm: bootstrap estimate of $\widehat{se}(r)$

**Step 1**: Let $B$ be the number of bootstrap samples taken. With $n = 15$, do SRSWR from schools 1 to 15.

\begin{equation}
\begin{aligned}
B^*_1 &= \left\{(X^*_{11}, Y^*_{11}), (X^*_{21}, Y^*_{21}), \ldots, (X^*_{n1}, Y^*_{n1})\right\} \\
B^*_2 &= \left\{(X^*_{12}, Y^*_{12}), (X^*_{22}, Y^*_{22}), \ldots, (X^*_{n2}, Y^*_{n2})\right\} \\
\vdots &= \vdots \\
B^*_{B} &= \left\{(X^*_{1B}, Y^*_{1B}), (X^*_{2B}, Y^*_{2B}), \ldots, (X^*_{nB}, Y^*_{nB})\right\} \\
\end{aligned}
\end{equation}  


**Step 2**: Let $S^*_{x_b}$ and $S^*_{y_b}$ be the standard deviations of the variables, $X^*_b$ and $Y^*_b$, respectively, where $b = \left\{1, 2, \ldots, B\right\}$. Calculate the pearson product coefficient of correlation, $r^*_b$

\begin{equation}
\begin{aligned}
r_b^* &= \frac{\frac{1}{n-1} \sum_{i = 1}^n \left(X^*_{ib} - {\bar{X}}_b^*\right) \left(Y_{ib}^* - {\bar{Y}}^*_b\right) }{ S^*_{x_b} S^*_{y_b}}
\end{aligned}
\end{equation}

to yield

\begin{equation}
\begin{aligned}
r &= \left\{r^*_1, r^*_2, \ldots, r^*_B\right\} 
\end{aligned}
\end{equation}

**Step 3**: Calculate bootstrap estimate of $\widehat{se}(r)$ using

\begin{equation}
\begin{aligned}
\widehat{se}(r) &= \sqrt{ \frac{\sum_{b=1}^B \left( r_b^* - {\bar{r}}^* \right)^2}{B-1} }
\end{aligned}
\end{equation}

## Algorithm implementation: bootstrap estimate of $\widehat{se}(r)$

```{r results = "hide"}
source("../R/s01_i01_load_data.R")
```

```{r se}
R0201 <- "../R/s02_i01_bs_sampling.R"
source(R0201)
```

```{r algo}
cat(paste0("    CODE FILENAME: ", R0201))
cat(paste(readLines(R0201), collapse="\n"),collapse = "\n")
```

  i.  bootstrap estimate of the standard error of $r$: `r se_r_boot`
  ii. 95% confidence interval for $\rho$ (the true population correlation): (`r ci_r_boot`)
  iii. a histogram showing the bootstrap distribution of the correlation $r$

```{r}
hist(r)
```

## Change maximum $r^*_b$ and recompute bootstrap estimate of $\widehat{se}(r)$

```{r}
R0301 <- "../R/s03_i01_max_value.R"
source(R0301)
```

```{r}
cat(paste0("    CODE FILENAME: ", R0301))
cat(paste(readLines(R0301), collapse="\n"),collapse = "\n")
```

The original maximum of $r^*_b$'s is `r r_max` while the new one is `r r_replaced_max`. Calculating the new $\widehat{se}(r^*)$ gives the value `r se_r_replaced_boot`. This meant an increase of `r se_percent_change`% compared to the original value.